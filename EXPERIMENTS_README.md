# V2AIX æ•°æ®å®žéªŒä½¿ç”¨æŒ‡å—

## ðŸ“Š æ•°æ®æ–‡ä»¶æ¦‚è§ˆ

å¤„ç†åŽçš„æ•°æ®ä½äºŽï¼š`output/processed_full/`

| æ–‡ä»¶ | è¡Œæ•° | å¤§å° | è¯´æ˜Ž |
|------|------|------|------|
| **trajectories.parquet** | 5,167,996 | 123 MB | è½¦è¾†è½¨è¿¹æ•°æ®ï¼ˆ1Hzé‡é‡‡æ ·ï¼‰ |
| **v2x_messages.parquet** | 1,099,678 | 6.6 MB | V2Xé€šä¿¡æ¶ˆæ¯ |
| **fused_data.parquet** | 5,167,996 | 116 MB | **èžåˆæ•°æ®ï¼ˆæŽ¨èä½¿ç”¨ï¼‰** |

---

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€æ•°æ®åŠ è½½

```python
import pandas as pd

# åŠ è½½èžåˆæ•°æ®ï¼ˆæœ€å¸¸ç”¨ï¼‰
fused = pd.read_parquet("output/processed_full/fused_data.parquet")

# è½¬æ¢æ—¶é—´æˆ³
fused['timestamp'] = pd.to_datetime(fused['timestamp_ms'], unit='ms')

print(f"æ€»è®°å½•æ•°: {len(fused):,}")
print(f"è½¦è¾†æ•°: {fused['vehicle_id'].nunique()}")
print(fused.head())
```

### 2. æ•°æ®å­—æ®µè¯´æ˜Ž

#### trajectories.parquetï¼ˆè½¨è¿¹æ•°æ®ï¼‰
```python
- timestamp_ms: int64          # æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
- vehicle_id: string           # è½¦è¾†ID
- latitude: float64            # çº¬åº¦ï¼ˆWGS84ï¼‰
- longitude: float64           # ç»åº¦ï¼ˆWGS84ï¼‰
- altitude: float64            # æµ·æ‹”é«˜åº¦ï¼ˆç±³ï¼‰
- speed_mps: float64          # é€Ÿåº¦ï¼ˆç±³/ç§’ï¼Œå¯èƒ½ä¸ºç©ºï¼‰
- heading_deg: float64        # èˆªå‘è§’ï¼ˆåº¦ï¼Œå¯èƒ½ä¸ºç©ºï¼‰
- topic: string               # æ•°æ®æºtopic
```

#### v2x_messages.parquetï¼ˆV2Xæ¶ˆæ¯ï¼‰
```python
- timestamp_ms: int64          # æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
- vehicle_id: string           # å‘é€è½¦è¾†ID
- message_type: string         # æ¶ˆæ¯ç±»åž‹ï¼ˆCAM/DENM/UNKNOWNï¼‰
- message_size_bytes: int64    # æ¶ˆæ¯å¤§å°ï¼ˆå­—èŠ‚ï¼‰
- latency_ms: float64         # å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼Œå¯èƒ½ä¸ºç©ºï¼‰
- rssi_dbm: float64           # ä¿¡å·å¼ºåº¦ï¼ˆdBmï¼Œå¯èƒ½ä¸ºç©ºï¼‰
- topic: string               # æ•°æ®æºtopic
```

#### fused_data.parquetï¼ˆèžåˆæ•°æ®ï¼ŒæŽ¨èï¼‰
```python
- timestamp_ms: int64          # æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
- vehicle_id: string           # è½¦è¾†ID
- latitude: float64            # çº¬åº¦
- longitude: float64           # ç»åº¦
- altitude: float64            # æµ·æ‹”é«˜åº¦
- speed_mps: float64          # é€Ÿåº¦
- heading_deg: float64        # èˆªå‘è§’
- messages_sent: int64        # è¯¥æ—¶åˆ»å‘é€çš„æ¶ˆæ¯æ•°
- total_bytes_sent: int64     # è¯¥æ—¶åˆ»å‘é€çš„æ€»å­—èŠ‚æ•°
- avg_latency_ms: float64     # å¹³å‡å»¶è¿Ÿ
- message_types: string       # æ¶ˆæ¯ç±»åž‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰
```

---

## ðŸ§ª å…¸åž‹å®žéªŒåœºæ™¯

### åœºæ™¯1: é€šä¿¡è¦†ç›–èŒƒå›´åˆ†æž

```python
import pandas as pd
import matplotlib.pyplot as plt

fused = pd.read_parquet("output/processed_full/fused_data.parquet")

# æ‰¾å‡ºæœ‰é€šä¿¡æ´»åŠ¨çš„åŒºåŸŸ
active = fused[fused['messages_sent'] > 0]

# ç»˜åˆ¶é€šä¿¡çƒ­åŠ›å›¾
plt.figure(figsize=(12, 8))
plt.scatter(active['longitude'], active['latitude'],
            c=active['messages_sent'], cmap='hot', alpha=0.6, s=1)
plt.colorbar(label='Messages Sent')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('V2X Communication Coverage')
plt.savefig('communication_heatmap.png', dpi=300)
plt.show()
```

### åœºæ™¯2: è½¦è¾†é€šä¿¡è¡Œä¸ºåˆ†æž

```python
# ç»Ÿè®¡æ¯è¾†è½¦çš„é€šä¿¡æƒ…å†µ
vehicle_stats = fused.groupby('vehicle_id').agg({
    'messages_sent': 'sum',
    'total_bytes_sent': 'sum',
    'latitude': ['min', 'max'],
    'longitude': ['min', 'max']
}).reset_index()

# è®¡ç®—ç§»åŠ¨èŒƒå›´
vehicle_stats['mobility_range'] = (
    (vehicle_stats[('latitude', 'max')] - vehicle_stats[('latitude', 'min')])**2 +
    (vehicle_stats[('longitude', 'max')] - vehicle_stats[('longitude', 'min')])**2
) ** 0.5

print(vehicle_stats.describe())
```

### åœºæ™¯3: æ—¶é—´æ¨¡å¼åˆ†æž

```python
v2x = pd.read_parquet("output/processed_full/v2x_messages.parquet")
v2x['timestamp'] = pd.to_datetime(v2x['timestamp_ms'], unit='ms')

# æŒ‰å°æ—¶ç»Ÿè®¡æ¶ˆæ¯é‡
v2x['hour'] = v2x['timestamp'].dt.hour
hourly_msgs = v2x.groupby('hour').size()

# ç»˜åˆ¶æ—¶é—´åˆ†å¸ƒ
hourly_msgs.plot(kind='bar', figsize=(12, 6))
plt.xlabel('Hour of Day')
plt.ylabel('Number of Messages')
plt.title('V2X Message Temporal Pattern')
plt.savefig('temporal_pattern.png', dpi=300)
plt.show()
```

### åœºæ™¯4: æ¶ˆæ¯ç±»åž‹åˆ†æž

```python
# æ¶ˆæ¯ç±»åž‹ç»Ÿè®¡
msg_types = v2x.groupby('message_type').agg({
    'message_size_bytes': ['count', 'mean', 'std', 'min', 'max']
})

print("æ¶ˆæ¯ç±»åž‹ç»Ÿè®¡:")
print(msg_types)

# æ¶ˆæ¯ç±»åž‹åˆ†å¸ƒé¥¼å›¾
v2x['message_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('V2X Message Type Distribution')
plt.savefig('message_type_distribution.png', dpi=300)
plt.show()
```

### åœºæ™¯5: ç©ºé—´ç½‘æ ¼åˆ†æž

```python
# åˆ›å»ºç©ºé—´ç½‘æ ¼ï¼ˆ0.001åº¦çº¦110ç±³ï¼‰
grid_size = 0.001
fused['lat_grid'] = (fused['latitude'] / grid_size).astype(int)
fused['lon_grid'] = (fused['longitude'] / grid_size).astype(int)

# ç»Ÿè®¡æ¯ä¸ªç½‘æ ¼çš„é€šä¿¡å¯†åº¦
grid_density = fused.groupby(['lat_grid', 'lon_grid']).agg({
    'messages_sent': 'sum',
    'vehicle_id': 'nunique'
}).reset_index()

# æ‰¾å‡ºçƒ­ç‚¹åŒºåŸŸ
hotspots = grid_density.nlargest(10, 'messages_sent')
print("é€šä¿¡çƒ­ç‚¹åŒºåŸŸ:")
print(hotspots)
```

### åœºæ™¯6: è½¨è¿¹-æ¶ˆæ¯æ—¶ç©ºå…³è”

```python
# åŠ è½½ä¸¤ä¸ªæ•°æ®é›†
trajectories = pd.read_parquet("output/processed_full/trajectories.parquet")
v2x_messages = pd.read_parquet("output/processed_full/v2x_messages.parquet")

# æŒ‰æ—¶é—´æˆ³å’Œè½¦è¾†IDåˆå¹¶ï¼ˆå®¹å·®1ç§’ï¼‰
merged = pd.merge_asof(
    v2x_messages.sort_values('timestamp_ms'),
    trajectories.sort_values('timestamp_ms'),
    on='timestamp_ms',
    by='vehicle_id',
    direction='nearest',
    tolerance=1000  # 1ç§’
)

print(f"æˆåŠŸå…³è”çš„æ¶ˆæ¯æ•°: {len(merged[merged['latitude'].notna()]):,}")
```

---

## ðŸ“ˆ é«˜çº§åˆ†æžç¤ºä¾‹

### å®Œæ•´åˆ†æžè„šæœ¬

è¿è¡Œå®Œæ•´çš„åˆ†æžæµç¨‹ï¼š

```bash
python3 data_usage_guide.py
```

è¿™å°†æ‰§è¡Œï¼š
- åŸºç¡€æ•°æ®ç»Ÿè®¡
- é€šä¿¡è¦†ç›–åˆ†æž
- æ—¶é—´æ¨¡å¼åˆ†æž
- è½¦è¾†è¡Œä¸ºåˆ†æž
- æ¶ˆæ¯ç±»åž‹åˆ†æž
- ç©ºé—´å¯†åº¦åˆ†æž

### è‡ªå®šä¹‰åˆ†æž

å‚è€ƒ `data_usage_guide.py` ä¸­çš„å®žéªŒå‡½æ•°ï¼š
- `experiment_1_communication_coverage()` - é€šä¿¡è¦†ç›–
- `experiment_2_temporal_patterns()` - æ—¶é—´æ¨¡å¼
- `experiment_3_vehicle_behavior()` - è½¦è¾†è¡Œä¸º
- `experiment_4_message_types()` - æ¶ˆæ¯ç±»åž‹
- `experiment_5_spatial_temporal_join()` - æ—¶ç©ºå…³è”
- `experiment_6_communication_density()` - ç©ºé—´å¯†åº¦

---

## ðŸ’¡ ä½¿ç”¨å»ºè®®

### æŽ¨èä½¿ç”¨ fused_data.parquet

**åŽŸå› ï¼š**
- âœ… åŒ…å«å®Œæ•´çš„è½¨è¿¹ä¿¡æ¯
- âœ… å·²èšåˆé€šä¿¡ç»Ÿè®¡ï¼ˆæŒ‰æ—¶é—´ç‚¹ï¼‰
- âœ… å‡å°‘äº†æ•°æ®å…³è”æ“ä½œ
- âœ… æ›´é€‚åˆå¤§å¤šæ•°åˆ†æžåœºæ™¯

**é€‚åˆåœºæ™¯ï¼š**
- é€šä¿¡è¡Œä¸ºä¸Žä½ç½®å…³è”åˆ†æž
- ç©ºé—´é€šä¿¡å¯†åº¦åˆ†æž
- è½¦è¾†ç§»åŠ¨æ¨¡å¼åˆ†æž
- æ—¶ç©ºç‰¹å¾æå–

### ä½•æ—¶ä½¿ç”¨å•ç‹¬æ–‡ä»¶

**trajectories.parquetï¼š**
- åªå…³æ³¨è½¨è¿¹æ•°æ®
- ä¸éœ€è¦é€šä¿¡ä¿¡æ¯
- è½¨è¿¹æ’å€¼/å¹³æ»‘
- ç§»åŠ¨æ¨¡å¼èšç±»

**v2x_messages.parquetï¼š**
- åªåˆ†æžé€šä¿¡å±‚é¢
- æ¶ˆæ¯å†…å®¹åˆ†æž
- åè®®å±‚ç ”ç©¶
- ç½‘ç»œæ€§èƒ½è¯„ä¼°

---

## ðŸ”§ å¸¸ç”¨å·¥å…·å‡½æ•°

```python
# æ—¶é—´èŒƒå›´è¿‡æ»¤
def filter_time_range(df, start_time, end_time):
    df['timestamp'] = pd.to_datetime(df['timestamp_ms'], unit='ms')
    return df[(df['timestamp'] >= start_time) & (df['timestamp'] <= end_time)]

# åœ°ç†èŒƒå›´è¿‡æ»¤
def filter_bbox(df, min_lon, min_lat, max_lon, max_lat):
    return df[
        (df['longitude'] >= min_lon) & (df['longitude'] <= max_lon) &
        (df['latitude'] >= min_lat) & (df['latitude'] <= max_lat)
    ]

# è®¡ç®—ä¸¤ç‚¹è·ç¦»ï¼ˆç®€åŒ–ç‰ˆï¼‰
def haversine_distance(lat1, lon1, lat2, lon2):
    from math import radians, sin, cos, sqrt, atan2
    R = 6371000  # åœ°çƒåŠå¾„ï¼ˆç±³ï¼‰
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    return R * c
```

---

## ðŸ“š ç›¸å…³æ–‡æ¡£

- **é¡¹ç›®é…ç½®**: `config_full_dataset.yaml`
- **å¤„ç†æ—¥å¿—**: `output/process_full.log`
- **å®Œæ•´ä½¿ç”¨ç¤ºä¾‹**: `data_usage_guide.py`
- **æ•°æ®é›†è®ºæ–‡**: [V2AIX Dataset (IEEE)](https://ieeexplore.ieee.org/document/10920150)

---

## â“ å¸¸è§é—®é¢˜

**Q: æ•°æ®é‡å¤ªå¤§ï¼Œå†…å­˜ä¸å¤Ÿæ€Žä¹ˆåŠžï¼Ÿ**
```python
# ä½¿ç”¨chunkingè¯»å–
for chunk in pd.read_parquet('fused_data.parquet', chunksize=100000):
    # å¤„ç†chunk
    process(chunk)
```

**Q: å¦‚ä½•åªåŠ è½½ç‰¹å®šåˆ—ï¼Ÿ**
```python
df = pd.read_parquet('fused_data.parquet',
                      columns=['timestamp_ms', 'vehicle_id', 'messages_sent'])
```

**Q: å¦‚ä½•å¯¼å‡ºä¸ºCSVï¼Ÿ**
```python
df.to_csv('output.csv', index=False)
```

---

**ç¥å®žéªŒé¡ºåˆ©ï¼** ðŸŽ‰
